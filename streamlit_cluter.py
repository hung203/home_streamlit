import datetime
from sklearn.decomposition import PCA
import streamlit as st
import mlflow
import mlflow.sklearn
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.metrics import adjusted_rand_score, davies_bouldin_score, normalized_mutual_info_score, silhouette_score
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt
import random
import pandas as pd
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import cv2
import plotly.express as px
import plotly.graph_objects as go

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay MNIST v·ªõi Streamlit v√† MLflow")

# Cache d·ªØ li·ªáu MNIST
@st.cache_data
def load_mnist_data(sample_size):
    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    X, y = mnist.data / 255.0, mnist.target.astype(int)
    total_samples = mnist.data.shape[0]
    if sample_size < total_samples:
        X, _, y, _ = train_test_split(X, y, train_size=sample_size / total_samples, random_state=42, stratify=y)
    return X, y, total_samples

# T·∫°o c√°c tab
tab1, tab2, tab3 = st.tabs(["L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m", "Hu·∫•n luy·ªán", "MLflow"])

# ------------------------
# Tab 1: L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m
# ------------------------
with tab1:    
    st.header("üìå L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m", divider="blue")
    st.subheader("1Ô∏è‚É£ Ph√¢n c·ª•m l√† g√¨?")
    st.write("""
    Ph√¢n c·ª•m (Clustering) l√† m·ªôt k·ªπ thu·∫≠t h·ªçc m√°y kh√¥ng gi√°m s√°t, nh·∫±m nh√≥m c√°c ƒëi·ªÉm d·ªØ li·ªáu c√≥ ƒë·∫∑c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng v√†o c√πng m·ªôt c·ª•m.  
    üîç **ƒêi·ªÉm kh√°c bi·ªát v·ªõi ph√¢n lo·∫°i:**  
    - Ph√¢n c·ª•m kh√¥ng c√≥ nh√£n tr∆∞·ªõc (unsupervised).  
    - T·ª± ƒë·ªông t√¨m ra c·∫•u tr√∫c ·∫©n trong d·ªØ li·ªáu d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng.
    """)

    st.subheader("2Ô∏è‚É£ C√°c thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn", divider="blue")
    st.markdown("### üîπ Thu·∫≠t to√°n K-Means")
    st.write("K-Means l√† m·ªôt trong nh·ªØng thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn nh·∫•t. D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc th·ª±c hi·ªán:")
    st.markdown("#### **B∆∞·ªõc 1: Kh·ªüi t·∫°o K t√¢m c·ª•m ban ƒë·∫ßu**")
    st.write("Ch·ªçn ng·∫´u nhi√™n **K ƒëi·ªÉm** t·ª´ t·∫≠p d·ªØ li·ªáu l√†m t√¢m c·ª•m ban ƒë·∫ßu.")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/K_Means_Example_Step_1.svg/1024px-K_Means_Example_Step_1.svg.png", caption="Minh h·ªça b∆∞·ªõc 1")
    st.markdown("#### **B∆∞·ªõc 2: G√°n ƒëi·ªÉm d·ªØ li·ªáu v√†o c·ª•m g·∫ßn nh·∫•t**")
    st.write("- T√≠nh **kho·∫£ng c√°ch** (th∆∞·ªùng l√† kho·∫£ng c√°ch Euclid) t·ª´ m·ªói ƒëi·ªÉm d·ªØ li·ªáu ƒë·∫øn t·ª´ng t√¢m c·ª•m.")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/K_Means_Example_Step_2.svg/1024px-K_Means_Example_Step_2.svg.png", caption="Minh h·ªça b∆∞·ªõc 2")
    st.markdown("#### **B∆∞·ªõc 3: C·∫≠p nh·∫≠t l·∫°i t√¢m c·ª•m**")
    st.write("- T√≠nh **trung b√¨nh t·ªça ƒë·ªô** c·ªßa t·∫•t c·∫£ c√°c ƒëi·ªÉm trong c√πng m·ªôt c·ª•m.")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/K_Means_Example_Step_3.svg/1024px-K_Means_Example_Step_3.svg.png", caption="Minh h·ªça b∆∞·ªõc 3")
    st.markdown("#### **B∆∞·ªõc 4: L·∫∑p l·∫°i b∆∞·ªõc 2 v√† 3**")
    st.write("- Ti·∫øp t·ª•c g√°n l·∫°i c√°c ƒëi·ªÉm d·ªØ li·ªáu v√†o c·ª•m g·∫ßn nh·∫•t.")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/K_Means_Example_Step_4.svg/1024px-K_Means_Example_Step_4.svg.png", caption="Minh h·ªça b∆∞·ªõc 4")
    st.markdown("#### **B∆∞·ªõc 5: D·ª´ng thu·∫≠t to√°n**")
    st.write("- Thu·∫≠t to√°n d·ª´ng khi t√¢m c·ª•m kh√¥ng c√≤n thay ƒë·ªïi ho·∫∑c ƒë·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa.")
    st.markdown("### üé® L∆∞u √Ω quan tr·ªçng v·ªÅ K-Means")
    st.write("""
    - **∆Øu ƒëi·ªÉm:** ƒê∆°n gi·∫£n, nhanh, hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu h√¨nh c·∫ßu.  
    - **Nh∆∞·ª£c ƒëi·ªÉm:** C·∫ßn ch·ªçn K tr∆∞·ªõc, nh·∫°y c·∫£m v·ªõi t√¢m ban ƒë·∫ßu, kh√¥ng hi·ªáu qu·∫£ v·ªõi c·ª•m ph·ª©c t·∫°p.
    """)

    st.subheader("üîπ Thu·∫≠t to√°n DBSCAN l√† g√¨?")
    st.write("""
    DBSCAN (Density-Based Spatial Clustering of Applications with Noise) l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô, ph√°t hi·ªán c·ª•m b·∫•t k·ª≥ h√¨nh d·∫°ng v√† nhi·ªÖu.  
    - **Eps (Œµ):** Kho·∫£ng c√°ch t·ªëi ƒëa ƒë·ªÉ hai ƒëi·ªÉm ƒë∆∞·ª£c coi l√† l√¢n c·∫≠n.  
    - **MinPts:** S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ h√¨nh th√†nh c·ª•m.
    """)

    st.subheader("2Ô∏è‚É£ C√°c b∆∞·ªõc ho·∫°t ƒë·ªông c·ªßa thu·∫≠t to√°n DBSCAN", divider="blue")
    st.markdown("#### **B∆∞·ªõc 1: X√°c ƒë·ªãnh c√°c tham s·ªë Eps v√† MinPts**")
    st.write("- Ch·ªçn **Eps (Œµ)** v√† **MinPts** ƒë·ªÉ x√°c ƒë·ªãnh ƒëi·ªÉm l√µi.")
    st.markdown("#### **B∆∞·ªõc 2: Ph√¢n lo·∫°i c√°c ƒëi·ªÉm d·ªØ li·ªáu**")
    st.write("- **ƒêi·ªÉm l√µi:** C√≥ √≠t nh·∫•t MinPts ƒëi·ªÉm trong b√°n k√≠nh Eps.  \n- **ƒêi·ªÉm bi√™n:** Trong Eps c·ªßa ƒëi·ªÉm l√µi.  \n- **ƒêi·ªÉm nhi·ªÖu:** Kh√¥ng thu·ªôc c·ª•m n√†o.")
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/1280px-DBSCAN-Illustration.svg.png")
    st.markdown("#### **B∆∞·ªõc 3: X√¢y d·ª±ng c·ª•m t·ª´ c√°c ƒëi·ªÉm l√µi**")
    st.write("- B·∫Øt ƒë·∫ßu t·ª´ ƒëi·ªÉm l√µi, m·ªü r·ªông c·ª•m v·ªõi c√°c ƒëi·ªÉm l√¢n c·∫≠n.")
    st.image("https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/db12.png")
    st.markdown("#### **B∆∞·ªõc 4: X·ª≠ l√Ω c√°c ƒëi·ªÉm ch∆∞a ƒë∆∞·ª£c g√°n nh√£n**")
    st.write("- Ti·∫øp t·ª•c t·∫°o c·ª•m m·ªõi ho·∫∑c ƒë√°nh d·∫•u nhi·ªÖu.")
    st.markdown("#### **B∆∞·ªõc 5: D·ª´ng thu·∫≠t to√°n**")
    st.write("- D·ª´ng khi t·∫•t c·∫£ ƒëi·ªÉm ƒë∆∞·ª£c x·ª≠ l√Ω.")
    st.markdown("### üé® L∆∞u √Ω quan tr·ªçng v·ªÅ DBSCAN")
    st.write("""
    - **∆Øu ƒëi·ªÉm:** Kh√¥ng c·∫ßn ch·ªçn s·ªë c·ª•m, ph√°t hi·ªán nhi·ªÖu.  
    - **Nh∆∞·ª£c ƒëi·ªÉm:** Nh·∫°y c·∫£m v·ªõi Eps v√† MinPts, kh√≥ v·ªõi d·ªØ li·ªáu chi·ªÅu cao.
    """)

    st.subheader("3Ô∏è‚É£ ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ph√¢n c·ª•m")
    st.write("C√°c ch·ªâ s·ªë ƒë√°nh gi√°:")
    st.markdown("- **Silhouette Score**: ƒêo m·ª©c ƒë·ªô t√°ch bi·ªát gi·ªØa c√°c c·ª•m.")
    st.image("image/Screenshot 2025-03-03 084601.png")
    st.markdown("- **Adjusted Rand Index (ARI)**: So s√°nh v·ªõi nh√£n th·ª±c t·∫ø.")
    st.image("image/Screenshot 2025-03-03 084611.png")
    st.markdown("- **Davies-Bouldin Index**: ƒê√°nh gi√° s·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c c·ª•m.")
    st.image("image/Screenshot 2025-03-03 084626.png")

# ------------------------
# Tab 2: Hu·∫•n luy·ªán
# ------------------------
with tab2:
    st.header("1. Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán")

    if "mnist_loaded" not in st.session_state:
        st.session_state.mnist_loaded = False
        st.session_state.total_samples = 70000

    # Fragment cho t·∫£i d·ªØ li·ªáu
    @st.fragment
    def load_data_interface():
        sample_size = st.number_input(
            "Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu s·ª≠ d·ª•ng", 
            min_value=1000, 
            max_value=st.session_state.total_samples, 
            value=10000, 
            step=1000
        )
        if st.button("T·∫£i d·ªØ li·ªáu MNIST"):
            X, y, total_samples = load_mnist_data(sample_size)
            X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)
            st.session_state.X = X
            st.session_state.y = y
            st.session_state.X_train = X_train
            st.session_state.y_train = y_train
            st.session_state.X_valid = X_valid
            st.session_state.y_valid = y_valid
            st.session_state.mnist_loaded = True
            st.session_state.selected_sample_size = sample_size
            st.write(f"D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªõi {sample_size} m·∫´u!")

    load_data_interface()

    # Hi·ªÉn th·ªã h√¨nh ·∫£nh minh h·ªça
    st.subheader("V√≠ d·ª• m·ªôt v√†i h√¨nh ·∫£nh minh h·ªça")
    if st.session_state.mnist_loaded:
        X = st.session_state.X
        y = st.session_state.y

        # Fragment cho hi·ªÉn th·ªã ·∫£nh
        @st.fragment
        def show_example_images():
            if st.button("üîÑ Hi·ªÉn th·ªã ·∫£nh m·ªõi"):
                st.session_state.example_images = random.sample(range(len(X)), 5)
            indices = st.session_state.get("example_images", random.sample(range(len(X)), 5))
            fig, axs = plt.subplots(1, 5, figsize=(12, 3))
            for i, idx in enumerate(indices):
                img = X[idx].reshape(28, 28)
                axs[i].imshow(img, cmap='gray')
                axs[i].axis('off')
                axs[i].set_title(f"Label: {y[idx]}")
            st.pyplot(fig)

        show_example_images()
    else:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi hi·ªÉn th·ªã h√¨nh ·∫£nh!")

    st.header("Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh")
    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh ph√¢n c·ª•m", ["K-means", "DBSCAN"], key="model_choice_cluster")
    
    if model_choice == "K-means":
        n_clusters = st.number_input("Ch·ªçn s·ªë l∆∞·ª£ng clusters", min_value=2, max_value=20, value=10, step=1)
    elif model_choice == "DBSCAN":
        eps = st.number_input("Ch·ªçn gi√° tr·ªã eps", min_value=0.1, max_value=10.0, value=0.5, step=0.1)
        min_samples = st.number_input("Ch·ªçn s·ªë m·∫´u t·ªëi thi·ªÉu", min_value=1, max_value=20, value=5, step=1)

    experiment_name = st.text_input(
        "Nh·∫≠p t√™n cho th√≠ nghi·ªám MLflow", 
        value=f"{model_choice}_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}"
    )

    # Fragment cho hu·∫•n luy·ªán m√¥ h√¨nh
    @st.fragment
    def train_model():
        if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
            if not st.session_state.mnist_loaded:
                st.error("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán m√¥ h√¨nh!")
            else:
                X_train_used = st.session_state.X_train
                y_train_used = st.session_state.y_train
                X_valid = st.session_state.X_valid
                y_valid = st.session_state.y_valid

                with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    mlflow.set_experiment(experiment_name)
                    with mlflow.start_run():
                        mlflow.log_param("experiment_name", experiment_name)
                        mlflow.log_param("model", model_choice)

                        if model_choice == "K-means":
                            mlflow.log_param("n_clusters", n_clusters)
                            status_text.text("Kh·ªüi t·∫°o m√¥ h√¨nh K-means...")
                            model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, verbose=0)
                            progress_bar.progress(10)

                            status_text.text("ƒêang hu·∫•n luy·ªán K-means tr√™n t·∫≠p hu·∫•n luy·ªán...")
                            model.fit(X_train_used)
                            progress_bar.progress(50)

                            status_text.text("D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra...")
                            y_pred = model.predict(X_valid)
                            progress_bar.progress(70)

                            status_text.text("ƒêang ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh...")
                            ari = adjusted_rand_score(y_valid, y_pred)
                            sil_score = silhouette_score(X_valid, y_pred) if len(np.unique(y_pred)) > 1 else -1
                            db_index = davies_bouldin_score(X_valid, y_pred) if len(np.unique(y_pred)) > 1 else -1
                            nmi = normalized_mutual_info_score(y_valid, y_pred)
                            progress_bar.progress(100)

                        elif model_choice == "DBSCAN":
                            mlflow.log_param("eps", eps)
                            mlflow.log_param("min_samples", min_samples)
                            status_text.text("Kh·ªüi t·∫°o m√¥ h√¨nh DBSCAN...")
                            model = DBSCAN(eps=eps, min_samples=min_samples)
                            progress_bar.progress(10)

                            status_text.text("ƒêang ph√¢n c·ª•m d·ªØ li·ªáu v·ªõi DBSCAN...")
                            model.fit(X_train_used)
                            progress_bar.progress(60)

                            status_text.text("ƒêang ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh...")
                            y_pred = model.labels_
                            ari = adjusted_rand_score(y_train_used, y_pred)
                            sil_score = silhouette_score(X_train_used, y_pred) if len(np.unique(y_pred)) > 1 else -1
                            db_index = davies_bouldin_score(X_train_used, y_pred) if len(np.unique(y_pred)) > 1 else -1
                            nmi = normalized_mutual_info_score(y_train_used, y_pred)
                            progress_bar.progress(100)

                        st.session_state.model = model
                        st.session_state.trained_model_name = model_choice
                        st.session_state.train_ari = ari
                        st.session_state.train_sil = sil_score
                        st.session_state.train_nmi = nmi
                        st.session_state.train_db = db_index

                        mlflow.log_metric("ARI", ari)
                        mlflow.log_metric("Silhouette", sil_score)
                        mlflow.log_metric("NMI", nmi)
                        mlflow.log_metric("DaviesBouldin", db_index)
                        mlflow.sklearn.log_model(model, "model")

                st.success("Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t!")
                st.session_state.experiment_name = experiment_name

    train_model()

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau khi hu·∫•n luy·ªán
    if "train_ari" in st.session_state:
        st.write("### K·∫øt qu·∫£ ph√¢n c·ª•m")
        labels = st.session_state.model.labels_ if model_choice == "DBSCAN" else st.session_state.model.predict(st.session_state.X_valid)
        unique_labels = np.unique(labels)
        st.write(f"**S·ªë l∆∞·ª£ng c·ª•m t√¨m th·∫•y:** {len(unique_labels) if -1 not in unique_labels else len(unique_labels) - 1}")
        cluster_counts = pd.Series(labels).value_counts()
        cluster_df = pd.DataFrame({"C·ª•m": cluster_counts.index, "S·ªë l∆∞·ª£ng ƒëi·ªÉm": cluster_counts.values})
        st.dataframe(cluster_df)
        if -1 in labels:
            noise_ratio = (labels == -1).mean() * 100
            st.write(f"**T·ª∑ l·ªá nhi·ªÖu:** {noise_ratio:.2f}%")
        if model_choice == "K-means":
            st.write(f"üîπ **Adjusted Rand Index (Validation):** {st.session_state.train_ari:.4f}")
        elif model_choice == "DBSCAN":
            st.write(f"üîπ **Adjusted Rand Index (Train):** {st.session_state.train_ari:.4f}")
        st.write(f"üîπ **Silhouette Score:** {st.session_state.train_sil:.4f}")
        st.write(f"üîπ **Normalized Mutual Information:** {st.session_state.train_nmi:.4f}")
        st.write(f"üîπ **Davies-Bouldin Index:** {st.session_state.train_db:.4f}")

        # Tr·ª±c quan ho√° ph√¢n c·ª•m v·ªõi PCA
        st.subheader("Tr·ª±c quan ho√° ph√¢n c·ª•m")
        X_vis = st.session_state.X_valid if model_choice == "K-means" else st.session_state.X_train
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_vis)

        df = pd.DataFrame({
            "PC1": X_pca[:, 0],
            "PC2": X_pca[:, 1],
            "C·ª•m": labels.astype(str)
        })
        df["C·ª•m"] = df["C·ª•m"].replace("-1", "Nhi·ªÖu")

        fig = px.scatter(
            df, x="PC1", y="PC2", color="C·ª•m",
            title=f"Tr·ª±c quan ph√¢n c·ª•m v·ªõi {model_choice}",
            labels={"PC1": "Th√†nh ph·∫ßn ch√≠nh 1", "PC2": "Th√†nh ph·∫ßn ch√≠nh 2"},
            color_discrete_sequence=px.colors.qualitative.T10 if len(unique_labels) <= 10 else px.colors.qualitative.Dark24
        )
        fig.update_layout(
            legend_title_text="C·ª•m", title_font_size=14,
            xaxis_title_font_size=12, yaxis_title_font_size=12,
            legend=dict(x=1.05, y=1)
        )
        st.plotly_chart(fig, use_container_width=True)

# ------------------------
# Tab 3: MLflow
# ------------------------
with tab3:
    st.header("Tracking MLflow")
    try:
        from mlflow.tracking import MlflowClient
        client = MlflowClient()
        experiments = mlflow.search_experiments()

        if experiments:
            st.write("#### Danh s√°ch th√≠ nghi·ªám")
            experiment_data = [{"Experiment ID": exp.experiment_id, "Experiment Name": exp.name, "Artifact Location": exp.artifact_location} for exp in experiments]
            df_experiments = pd.DataFrame(experiment_data)
            st.dataframe(df_experiments)

            selected_exp_name = st.selectbox("üîç Ch·ªçn th√≠ nghi·ªám ƒë·ªÉ xem chi ti·∫øt", options=[exp.name for exp in experiments])
            selected_exp_id = next(exp.experiment_id for exp in experiments if exp.name == selected_exp_name)
            runs = mlflow.search_runs(selected_exp_id)

            if not runs.empty:
                st.write("#### Danh s√°ch runs")
                st.dataframe(runs)
                selected_run_id = st.selectbox("üîç Ch·ªçn run ƒë·ªÉ xem chi ti·∫øt", options=runs["run_id"])
                run = mlflow.get_run(selected_run_id)

                st.write("##### Th√¥ng tin run")
                st.write(f"*Run ID:* {run.info.run_id}")
                st.write(f"*Experiment ID:* {run.info.experiment_id}")
                st.write(f"*Start Time:* {run.info.start_time}")
                st.write("##### Metrics")
                st.json(run.data.metrics)
                st.write("##### Params")
                st.json(run.data.params)

                artifacts = client.list_artifacts(selected_run_id)
                if artifacts:
                    st.write("##### Artifacts")
                    for artifact in artifacts:
                        st.write(f"- {artifact.path}")
            else:
                st.warning("Kh√¥ng c√≥ runs n√†o trong th√≠ nghi·ªám n√†y.")
        else:
            st.warning("Kh√¥ng c√≥ th√≠ nghi·ªám n√†o ƒë∆∞·ª£c t√¨m th·∫•y.")
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi l·∫•y danh s√°ch th√≠ nghi·ªám: {e}")
