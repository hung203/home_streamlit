import streamlit as st
import mlflow
import mlflow.sklearn
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.metrics import adjusted_rand_score, davies_bouldin_score, normalized_mutual_info_score, silhouette_score
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt
import random
import pandas as pd
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import cv2

# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay MNIST v·ªõi Streamlit v√† MLflow")

tab1, tab2, tab3 = st.tabs([
    "L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m",
    "Hu·∫•n luy·ªán",
    "Mlflow"
])

# ------------------------
# B∆∞·ªõc 1: X·ª≠ l√Ω d·ªØ li·ªáu
# ------------------------
with tab1:
    st.header("üìå L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m")
    
    st.subheader("1Ô∏è‚É£ Ph√¢n c·ª•m l√† g√¨?")
    st.write("""
    Ph√¢n c·ª•m (Clustering) l√† m·ªôt k·ªπ thu·∫≠t h·ªçc m√°y kh√¥ng gi√°m s√°t nh·∫±m nh√≥m c√°c ƒëi·ªÉm d·ªØ li·ªáu c√≥ ƒë·∫∑c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng v√†o c√πng m·ªôt c·ª•m. 
    Kh√°c v·ªõi ph√¢n lo·∫°i, ph√¢n c·ª•m kh√¥ng c√≥ nh√£n tr∆∞·ªõc m√† t·ª± ƒë·ªông t√¨m ra c·∫•u tr√∫c trong d·ªØ li·ªáu.
    """)

    st.subheader("2Ô∏è‚É£ C√°c thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn")
    
    st.markdown("### üîπ K-Means")
    st.write("""
    - K-Means l√† thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn, chia d·ªØ li·ªáu th√†nh K nh√≥m d·ª±a tr√™n kho·∫£ng c√°ch ƒë·∫øn tr·ªçng t√¢m (centroid).
    - Quy tr√¨nh:
        1. Ch·ªçn K c·ª•m ban ƒë·∫ßu.
        2. G√°n m·ªói ƒëi·ªÉm d·ªØ li·ªáu v√†o c·ª•m g·∫ßn nh·∫•t.""")
        
    st.image("image/Screenshot 2025-03-03 083928.png")     
    st.write("""3. T√≠nh l·∫°i tr·ªçng t√¢m cho t·ª´ng c·ª•m.""")

    st.image("image/Screenshot 2025-03-03 084527.png")
    st.write("""4. L·∫∑p l·∫°i cho ƒë·∫øn khi c√°c tr·ªçng t√¢m ·ªïn ƒë·ªãnh.
    """)
    
    st.markdown("### üîπ DBSCAN")
    st.write("""
    - **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) l√† thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô.

    ##### Quy tr√¨nh c·ªßa thu·∫≠t to√°n:
    1. Thu·∫≠t to√°n l·ª±a ch·ªçn m·ªôt ƒëi·ªÉm d·ªØ li·ªáu b·∫•t k·ª≥. Sau ƒë√≥ ti·∫øn h√†nh x√°c ƒë·ªãnh c√°c ƒëi·ªÉm l√µi v√† ƒëi·ªÉm bi√™n th√¥ng qua v√πng l√¢n c·∫≠n epsilon b·∫±ng c√°ch lan truy·ªÅn theo li√™n k·∫øt chu·ªói c√°c ƒëi·ªÉm thu·ªôc c√πng m·ªôt c·ª•m.  
    2. C·ª•m ho√†n to√†n ƒë∆∞·ª£c x√°c ƒë·ªãnh khi kh√¥ng th·ªÉ m·ªü r·ªông ƒë∆∞·ª£c th√™m. Khi ƒë√≥ l·∫∑p l·∫°i ƒë·ªá quy to√†n b·ªô qu√° tr√¨nh v·ªõi ƒëi·ªÉm kh·ªüi t·∫°o trong s·ªë c√°c ƒëi·ªÉm d·ªØ li·ªáu c√≤n l·∫°i ƒë·ªÉ x√°c ƒë·ªãnh m·ªôt c·ª•m m·ªõi.

    ### ∆Øu ƒëi·ªÉm:
    - Kh√¥ng c·∫ßn x√°c ƒë·ªãnh s·ªë c·ª•m tr∆∞·ªõc (kh√¥ng gi·ªëng K-Means).  
    - T·ªët trong vi·ªác ph√°t hi·ªán nhi·ªÖu.  

    ### Nh∆∞·ª£c ƒëi·ªÉm:
    - Nh·∫°y c·∫£m v·ªõi tham s·ªë `eps` (Epsilon - B√°n k√≠nh l√¢n c·∫≠n) v√† `min_samples` (S·ªë l∆∞·ª£ng ƒëi·ªÉm t·ªëi thi·ªÉu).
    """)
    st.subheader("3Ô∏è‚É£ ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ph√¢n c·ª•m")
    st.write("Sau khi ph√¢n c·ª•m, c√≥ nhi·ªÅu c√°ch ƒë√°nh gi√° k·∫øt qu·∫£:")
    
    st.markdown("- **Silhouette Score**: ƒêo l∆∞·ªùng m·ª©c ƒë·ªô t√°ch bi·ªát gi·ªØa c√°c c·ª•m.")
    st.image("image/Screenshot 2025-03-03 084601.png")
    st.markdown("- **Adjusted Rand Index (ARI)**: So s√°nh ph√¢n c·ª•m v·ªõi nh√£n th·ª±c t·∫ø (n·∫øu c√≥).")
    st.image("image/Screenshot 2025-03-03 084611.png")
    st.markdown("- **Davies-Bouldin Index**: ƒê√°nh gi√° s·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c c·ª•m.")
    st.image("image/Screenshot 2025-03-03 084626.png")

    
# ------------------------
# B∆∞·ªõc 2: Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh (Ph√¢n c·ª•m v·ªõi K-means & DBSCAN)
# ------------------------
with tab2:
    st.header("1. Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán")

    # Ki·ªÉm tra n·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i ch∆∞a
    if "mnist_loaded" not in st.session_state:
        mnist = fetch_openml('mnist_784', version=1, as_frame=False)
        st.session_state.total_samples = mnist.data.shape[0]  # T·ªïng s·ªë m·∫´u
        st.session_state.mnist_data = mnist  # L∆∞u d·ªØ li·ªáu g·ªëc
        st.session_state.mnist_loaded = False  # Ch∆∞a t·∫£i m·∫´u c·ª• th·ªÉ

    # Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u s·ª≠ d·ª•ng
    sample_size = st.number_input(
        "Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu s·ª≠ d·ª•ng", 
        min_value=1000, 
        max_value=st.session_state.total_samples, 
        value=st.session_state.total_samples, 
        step=1000
    )

    if st.button("T·∫£i d·ªØ li·ªáu MNIST"):
        mnist = st.session_state.mnist_data
        X, y = mnist.data / 255.0, mnist.target.astype(int)
        
        # Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu theo y√™u c·∫ßu
        if sample_size < st.session_state.total_samples:
            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42, stratify=y)
        
        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.X = X
        st.session_state.y = y
        st.session_state.mnist_loaded = True
        st.session_state.selected_sample_size = sample_size
        st.write(f"D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i v·ªõi {sample_size} m·∫´u!")

    # Hi·ªÉn th·ªã h√¨nh ·∫£nh minh h·ªça
    st.subheader("V√≠ d·ª• m·ªôt v√†i h√¨nh ·∫£nh minh h·ªça")
    
    if st.session_state.mnist_loaded:
        X = st.session_state.X
        y = st.session_state.y

        # N√∫t l√†m m·ªõi h√¨nh ·∫£nh
        if st.button("üîÑ Hi·ªÉn th·ªã ·∫£nh m·ªõi"):
            st.session_state.example_images = random.sample(range(len(X)), 5)

        indices = st.session_state.get("example_images", random.sample(range(len(X)), 5))

        fig, axs = plt.subplots(1, 5, figsize=(12, 3))
        for i, idx in enumerate(indices):
            img = X[idx].reshape(28, 28)
            axs[i].imshow(img, cmap='gray')
            axs[i].axis('off')
            axs[i].set_title(f"Label: {y[idx]}")
        
        st.pyplot(fig)
    else:
        st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi hi·ªÉn th·ªã h√¨nh ·∫£nh!")
        
    st.header("Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh")
    # Ng∆∞·ªùi d√πng ch·ªçn m√¥ h√¨nh ph√¢n c·ª•m
    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh ph√¢n c·ª•m", ["K-means", "DBSCAN"], key="model_choice_cluster")
    
    if model_choice == "K-means":
        n_clusters = st.number_input(
            "Ch·ªçn s·ªë l∆∞·ª£ng clusters", 
            min_value=2, 
            max_value=20, 
            value=10, 
            step=1,
            help="S·ªë l∆∞·ª£ng clusters l√† s·ªë nh√≥m d·ªØ li·ªáu m√† K-means s·∫Ω t√¨m ki·∫øm. V·ªõi MNIST, gi√° tr·ªã th√¥ng th∆∞·ªùng l√† 10."
        )
    elif model_choice == "DBSCAN":
        eps = st.number_input(
            "Ch·ªçn gi√° tr·ªã eps", 
            min_value=0.1, 
            max_value=10.0, 
            value=0.5, 
            step=0.1,
            help="Gi√° tr·ªã eps x√°c ƒë·ªãnh kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa c√°c ƒëi·ªÉm ƒë·ªÉ ƒë∆∞·ª£c xem l√† c√πng m·ªôt c·ª•m."
        )
        min_samples = st.number_input(
            "Ch·ªçn s·ªë m·∫´u t·ªëi thi·ªÉu", 
            min_value=1, 
            max_value=20, 
            value=5, 
            step=1,
            help="S·ªë m·∫´u t·ªëi thi·ªÉu xung quanh m·ªôt ƒëi·ªÉm c·∫ßn c√≥ ƒë·ªÉ ƒëi·ªÉm ƒë√≥ ƒë∆∞·ª£c xem l√† ƒëi·ªÉm l√µi c·ªßa m·ªôt c·ª•m."
        )
    
    # N√∫t hu·∫•n luy·ªán
    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):    
        X_train_used = st.session_state.X_train
        y_train_used = st.session_state.y_train
        X_valid = st.session_state.X_valid
        y_valid = st.session_state.y_valid

        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        experiment_name = f"Experiment_{model_choice}_{timestamp}"
        mlflow.set_experiment(experiment_name)
        # L∆∞u t√™n th√≠ nghi·ªám v√†o session_state v√† hi·ªÉn th·ªã ra giao di·ªán
        st.session_state.experiment_name = experiment_name
        st.write("T√™n th√≠ nghi·ªám:", experiment_name)
        with mlflow.start_run():
            mlflow.log_param("experiment_name", experiment_name)
            mlflow.log_param("model", model_choice)
            
            # V·ªõi K-means: hu·∫•n luy·ªán tr√™n t·∫≠p train v√† d·ª± ƒëo√°n tr√™n t·∫≠p validation
            if model_choice == "K-means":
                mlflow.log_param("n_clusters", n_clusters)
                model = KMeans(n_clusters=n_clusters, random_state=42)
                model.fit(X_train_used)
                y_pred = model.predict(X_valid)
                ari = adjusted_rand_score(y_valid, y_pred)
                
                # Ki·ªÉm tra s·ªë l∆∞·ª£ng cluster tr∆∞·ªõc khi t√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√°
                if len(np.unique(y_pred)) > 1:
                    sil_score = silhouette_score(X_valid, y_pred)
                    db_index = davies_bouldin_score(X_valid, y_pred)
                else:
                    sil_score = -1
                    db_index = -1
                
                nmi = normalized_mutual_info_score(y_valid, y_pred)
            
            # V·ªõi DBSCAN: hu·∫•n luy·ªán tr√™n t·∫≠p train (v√¨ kh√¥ng h·ªó tr·ª£ predict tr√™n d·ªØ li·ªáu m·ªõi)
            elif model_choice == "DBSCAN":
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)
                model = DBSCAN(eps=eps, min_samples=min_samples)
                model.fit(X_train_used)
                y_pred = model.labels_  # Nh√£n ph√¢n c·ª•m tr√™n t·∫≠p train
                ari = adjusted_rand_score(y_train_used, y_pred)
                
                if len(np.unique(y_pred)) > 1:
                    sil_score = silhouette_score(X_train_used, y_pred)
                    db_index = davies_bouldin_score(X_train_used, y_pred)
                else:
                    sil_score = -1
                    db_index = -1
                
                nmi = normalized_mutual_info_score(y_train_used, y_pred)
            
            # L∆∞u k·∫øt qu·∫£ v√† m√¥ h√¨nh v√†o session_state
            st.session_state.model = model
            st.session_state.trained_model_name = model_choice
            st.session_state.train_ari = ari
            st.session_state.train_sil = sil_score
            st.session_state.train_nmi = nmi
            st.session_state.train_db = db_index
            
            mlflow.log_metric("ARI", ari)
            mlflow.log_metric("Silhouette", sil_score)
            mlflow.log_metric("NMI", nmi)
            mlflow.log_metric("DaviesBouldin", db_index)
            mlflow.sklearn.log_model(model, "model")
    
        st.session_state.experiment_name = experiment_name
        st.write("T√™n th√≠ nghi·ªám:", experiment_name)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau khi hu·∫•n luy·ªán
    if "train_ari" in st.session_state:
        if model_choice == "K-means":
            st.write(f"üîπ **Adjusted Rand Index (Validation):** {st.session_state.train_ari:.4f}")
        elif model_choice == "DBSCAN":
            st.write(f"üîπ **Adjusted Rand Index (Train):** {st.session_state.train_ari:.4f}")
        st.write(f"üîπ **Silhouette Score:** {st.session_state.train_sil:.4f}")
        st.write(f"üîπ **Normalized Mutual Information:** {st.session_state.train_nmi:.4f}")
        st.write(f"üîπ **Davies-Bouldin Index:** {st.session_state.train_db:.4f}")
        
        # ------------------------
        # Tr·ª±c quan ho√° ph√¢n c·ª•m v·ªõi PCA
        # ------------------------
        st.subheader("Tr·ª±c quan ho√° ph√¢n c·ª•m")
        from sklearn.decomposition import PCA
        
        # Ch·ªçn t·∫≠p d·ªØ li·ªáu ph√π h·ª£p ƒë·ªÉ tr·ª±c quan ho√°
        if model_choice == "K-means":
            X_vis = X_valid
        else:
            X_vis = X_train_used
        
        # Gi·∫£m chi·ªÅu d·ªØ li·ªáu xu·ªëng 2D ƒë·ªÉ tr·ª±c quan ho√°
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_vis)
        
        fig, ax = plt.subplots()
        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap='viridis', s=10)
        ax.set_title(f"Tr·ª±c quan ph√¢n c·ª•m v·ªõi {model_choice}")
        plt.colorbar(scatter, ax=ax)
        
        st.pyplot(fig)
with tab3:
    st.header("Tracking MLflow")
    try:
        from mlflow.tracking import MlflowClient
        client = MlflowClient()

        # L·∫•y danh s√°ch th√≠ nghi·ªám t·ª´ MLflow
        experiments = mlflow.search_experiments()

        if experiments:
            st.write("#### Danh s√°ch th√≠ nghi·ªám")
            experiment_data = [
                {
                    "Experiment ID": exp.experiment_id,
                    "Experiment Name": exp.name,
                    "Artifact Location": exp.artifact_location
                }
                for exp in experiments
            ]
            df_experiments = pd.DataFrame(experiment_data)
            st.dataframe(df_experiments)

            # Ch·ªçn th√≠ nghi·ªám d·ª±a tr√™n T√äN thay v√¨ ID
            selected_exp_name = st.selectbox(
                "üîç Ch·ªçn th√≠ nghi·ªám ƒë·ªÉ xem chi ti·∫øt",
                options=[exp.name for exp in experiments]
            )

            # L·∫•y ID t∆∞∆°ng ·ª©ng v·ªõi t√™n ƒë∆∞·ª£c ch·ªçn
            selected_exp_id = next(exp.experiment_id for exp in experiments if exp.name == selected_exp_name)

            # L·∫•y danh s√°ch runs trong th√≠ nghi·ªám ƒë√£ ch·ªçn
            runs = mlflow.search_runs(selected_exp_id)
            if not runs.empty:
                st.write("#### Danh s√°ch runs")
                st.dataframe(runs)

                # Ch·ªçn run ƒë·ªÉ xem chi ti·∫øt
                selected_run_id = st.selectbox(
                    "üîç Ch·ªçn run ƒë·ªÉ xem chi ti·∫øt",
                    options=runs["run_id"]
                )

                # Hi·ªÉn th·ªã chi ti·∫øt run
                run = mlflow.get_run(selected_run_id)
                st.write("##### Th√¥ng tin run")
                st.write(f"*Run ID:* {run.info.run_id}")
                st.write(f"*Experiment ID:* {run.info.experiment_id}")
                st.write(f"*Start Time:* {run.info.start_time}")

                # Hi·ªÉn th·ªã metrics
                st.write("##### Metrics")
                st.json(run.data.metrics)

                # Hi·ªÉn th·ªã params
                st.write("##### Params")
                st.json(run.data.params)

                # Hi·ªÉn th·ªã artifacts s·ª≠ d·ª•ng client.list_artifacts
                artifacts = client.list_artifacts(selected_run_id)
                if artifacts:
                    st.write("##### Artifacts")
                    for artifact in artifacts:
                        st.write(f"- {artifact.path}")
            else:
                st.warning("Kh√¥ng c√≥ runs n√†o trong th√≠ nghi·ªám n√†y.")
        else:
            st.warning("Kh√¥ng c√≥ th√≠ nghi·ªám n√†o ƒë∆∞·ª£c t√¨m th·∫•y.")
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi l·∫•y danh s√°ch th√≠ nghi·ªám: {e}")
