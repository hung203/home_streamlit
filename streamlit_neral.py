import datetime
import random
import cv2
from matplotlib import patches
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import mlflow
import mlflow.pytorch
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from PIL import Image
from streamlit_drawable_canvas import st_canvas
# TiÃªu Ä‘á» á»©ng dá»¥ng
st.title("PhÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay MNIST vá»›i Neural_Netwwork")

# Táº¡o cÃ¡c tab
tab1, tab2, tab3, tab4 = st.tabs([
    "LÃ½ thuyáº¿t",
    "Huáº¥n luyá»‡n",
    "Dá»± ÄoÃ¡n",
    "MLflow"
])

# Tab 1: LÃ½ thuyáº¿t
import streamlit as st

with tab1:
    st.header("HÆ°á»›ng dáº«n: LÃ½ thuyáº¿t tá»•ng quÃ¡t vá» máº¡ng nÆ¡-ron ğŸ§ ")
    st.markdown("""
    Máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Artificial Neural Networks - ANN) lÃ  má»™t mÃ´ hÃ¬nh há»c mÃ¡y Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a nÃ£o bá»™ con ngÆ°á»i. NÃ³ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c há»i vÃ  dá»± Ä‘oÃ¡n tá»« dá»¯ liá»‡u thÃ´ng qua cÃ¡c lá»›p nÆ¡-ron káº¿t ná»‘i vá»›i nhau. DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c khÃ¡i niá»‡m vÃ  bÆ°á»›c hoáº¡t Ä‘á»™ng tá»•ng quÃ¡t:
    """)

    # Pháº§n 1: Cáº¥u trÃºc cÆ¡ báº£n
    st.markdown("""
    ### 1. Cáº¥u trÃºc cÆ¡ báº£n ğŸ› ï¸
    - **NÆ¡-ron (Neuron)** âš™ï¸: ÄÆ¡n vá»‹ tÃ­nh toÃ¡n cÆ¡ báº£n, nháº­n Ä‘áº§u vÃ o, xá»­ lÃ½, vÃ  táº¡o Ä‘áº§u ra.
    - **Lá»›p (Layers)** ğŸ“š:
      - **Lá»›p Ä‘áº§u vÃ o (Input Layer)** ğŸ“¥: Nháº­n dá»¯ liá»‡u thÃ´ (vÃ­ dá»¥: hÃ¬nh áº£nh, sá»‘ liá»‡u).
      - **Lá»›p áº©n (Hidden Layers)** ğŸ•µï¸: Xá»­ lÃ½ dá»¯ liá»‡u Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p.
      - **Lá»›p Ä‘áº§u ra (Output Layer)** ğŸ“¤: ÄÆ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng (vÃ­ dá»¥: phÃ¢n loáº¡i, dá»± Ä‘oÃ¡n sá»‘).
    - **Trá»ng sá»‘ (Weights)** âš–ï¸ vÃ  **Bias** ğŸ”§: CÃ¡c tham sá»‘ Ä‘iá»u chá»‰nh má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a Ä‘áº§u vÃ o, Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh há»c.
    """)
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/525px-Artificial_neural_network.svg.png", 
             caption="Cáº¥u trÃºc cÆ¡ báº£n cá»§a máº¡ng nÆ¡-ron: Lá»›p Ä‘áº§u vÃ o, lá»›p áº©n, vÃ  lá»›p Ä‘áº§u ra.", width=300)

    # Pháº§n 2: CÃ¡ch hoáº¡t Ä‘á»™ng
    st.markdown("""
    ### 2. CÃ¡ch hoáº¡t Ä‘á»™ng âš¡
    Máº¡ng nÆ¡-ron hoáº¡t Ä‘á»™ng thÃ´ng qua má»™t chuá»—i cÃ¡c bÆ°á»›c tuáº§n tá»±, tá»« viá»‡c nháº­n dá»¯ liá»‡u, xá»­ lÃ½, dá»± Ä‘oÃ¡n, Ä‘áº¿n Ä‘iá»u chá»‰nh Ä‘á»ƒ cáº£i thiá»‡n.
    """)

    st.markdown("""
    #### BÆ°á»›c 1: Nháº­n vÃ  truyá»n dá»¯ liá»‡u Ä‘áº§u vÃ o ğŸ“¡
    - Dá»¯ liá»‡u thÃ´ (vÃ­ dá»¥: hÃ¬nh áº£nh, sá»‘ liá»‡u) Ä‘Æ°á»£c Ä‘Æ°a vÃ o lá»›p Ä‘áº§u vÃ o.
    - Má»—i nÆ¡-ron trong lá»›p Ä‘áº§u vÃ o Ä‘áº¡i diá»‡n cho má»™t giÃ¡ trá»‹ cá»§a dá»¯ liá»‡u (vÃ­ dá»¥: má»™t pixel trong áº£nh).
    - Dá»¯ liá»‡u sau Ä‘Ã³ Ä‘Æ°á»£c truyá»n Ä‘áº¿n lá»›p áº©n Ä‘áº§u tiÃªn thÃ´ng qua cÃ¡c káº¿t ná»‘i cÃ³ trá»ng sá»‘.
    """)

    st.markdown("""
    #### BÆ°á»›c 2: TÃ­nh tá»•ng trá»ng sá»‘ táº¡i nÆ¡-ron â•
    - Táº¡i má»—i nÆ¡-ron trong lá»›p áº©n, dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘Æ°á»£c nhÃ¢n vá»›i trá»ng sá»‘ tÆ°Æ¡ng á»©ng vÃ  cá»™ng vá»›i bias:
    """)
    st.markdown(r"$$ z = W \cdot X + b $$")
    st.markdown("""
    Trong Ä‘Ã³:
    - $ W $: Ma tráº­n trá»ng sá»‘ (weights).
    - $ X $: Vector dá»¯ liá»‡u Ä‘áº§u vÃ o (inputs).
    - $ b $: GiÃ¡ trá»‹ bias (Ä‘iá»u chá»‰nh).
    - $ z $: Tá»•ng trá»ng sá»‘, Ä‘áº¡i diá»‡n cho giÃ¡ trá»‹ chÆ°a qua xá»­ lÃ½ cá»§a nÆ¡-ron.
    """)

    st.markdown("""
    #### BÆ°á»›c 3: Ãp dá»¥ng hÃ m kÃ­ch hoáº¡t ğŸš€
    """)
    st.markdown(r"- **ReLU**: $$ a = \max(0, z) $$ (chá»‰ giá»¯ giÃ¡ trá»‹ dÆ°Æ¡ng) ğŸ“ˆ")
    st.markdown(r"- **Sigmoid**: $$ a = \frac{1}{1 + e^{-z}} $$ (giá»›i háº¡n Ä‘áº§u ra tá»« 0 Ä‘áº¿n 1) ğŸ”¢")
    st.markdown(r"- **Tanh**: $$ a = \tanh(z) $$ (giá»›i háº¡n Ä‘áº§u ra tá»« -1 Ä‘áº¿n 1) ğŸ“‰")
    
    st.markdown("""
    - Äáº§u ra $ a $ cá»§a hÃ m kÃ­ch hoáº¡t lÃ  giÃ¡ trá»‹ cuá»‘i cÃ¹ng cá»§a nÆ¡-ron, Ä‘Æ°á»£c truyá»n sang lá»›p tiáº¿p theo.
    """)
    st.image("https://miro.medium.com/max/1200/1*XxxiA0jJvPrHEJHD4z893g.png", 
             caption="Ãp dá»¥ng hÃ m kÃ­ch hoáº¡t (ReLU, Sigmoid, Tanh).", width=400)

    st.markdown("""
    #### BÆ°á»›c 5: TÃ­nh hÃ m máº¥t mÃ¡t ğŸ“Š
    - So sÃ¡nh dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh vá»›i giÃ¡ trá»‹ thá»±c táº¿ Ä‘á»ƒ Ä‘o sai sá»‘ (loss).
    - VÃ­ dá»¥ hÃ m máº¥t mÃ¡t:
    """)
    st.markdown(r"- **Mean Squared Error (MSE)**: $$ L = \frac{1}{n} \sum (y - \hat{y})^2 $$ (cho há»“i quy)")
    st.markdown(r"- **Cross-Entropy Loss**: $$ L = -\frac{1}{n} \sum [y \cdot \log(\hat{y})] $$ (cho phÃ¢n loáº¡i)")
    
    st.markdown("""
    #### BÆ°á»›c 6: TÃ­nh gradient báº±ng lan truyá»n ngÆ°á»£c ğŸ”„
    """)
    st.markdown(r"$$ \frac{\partial L}{\partial W}, \frac{\partial L}{\partial b} $$")

    st.markdown("""
    #### BÆ°á»›c 7: Cáº­p nháº­t trá»ng sá»‘ ğŸ”§
    """)
    st.markdown(r"$$ W = W - \eta \cdot \frac{\partial L}{\partial W} $$")
    st.markdown(r"$$ b = b - \eta \cdot \frac{\partial L}{\partial b} $$")
    
    st.markdown("""
    Trong Ä‘Ã³:
    - $ \eta $: Tá»‘c Ä‘á»™ há»c (learning rate), quyáº¿t Ä‘á»‹nh bÆ°á»›c cáº­p nháº­t lá»›n hay nhá».
    """)

    st.markdown("""
    #### BÆ°á»›c 8: Láº·p láº¡i quÃ¡ trÃ¬nh huáº¥n luyá»‡n ğŸ”
    - Láº·p qua toÃ n bá»™ dá»¯ liá»‡u nhiá»u láº§n (epochs), chia thÃ nh cÃ¡c batch nhá» Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘ dáº§n dáº§n.
    - Sau má»—i láº§n láº·p, mÃ´ hÃ¬nh cáº£i thiá»‡n kháº£ nÄƒng dá»± Ä‘oÃ¡n báº±ng cÃ¡ch giáº£m hÃ m máº¥t mÃ¡t.
    """)

# Tab Huáº¥n luyá»‡n
with tab2:
    st.header("1. Chá»n kÃ­ch thÆ°á»›c vÃ  chia táº­p dá»¯ liá»‡u")
    
    # Khá»Ÿi táº¡o tráº¡ng thÃ¡i dá»¯ liá»‡u
    if "mnist_loaded" not in st.session_state:
        mnist = fetch_openml('mnist_784', version=1, as_frame=False)
        st.session_state.total_samples = mnist.data.shape[0]
        st.session_state.mnist_data = mnist
        st.session_state.mnist_loaded = False
        st.session_state.data_split_done = False

    sample_size = st.number_input(
        "Chá»n sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u", 
        min_value=1000, 
        max_value=st.session_state.total_samples, 
        value=10000, 
        step=1000,
        help="Sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u Ä‘Æ°á»£c láº¥y tá»« MNIST (tá»‘i Ä‘a 70,000)."
    )
    
    test_size = st.slider(
        "Chá»n tá»· lá»‡ dá»¯ liá»‡u Test", 
        0.1, 0.5, 0.2, 0.05,
        help="Tá»· lá»‡ dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ kiá»ƒm tra mÃ´ hÃ¬nh (10%-50%)."
    )
    valid_size = st.slider(
        "Chá»n tá»· lá»‡ dá»¯ liá»‡u Validation tá»« Train", 
        0.1, 0.3, 0.2, 0.05,
        help="Tá»· lá»‡ dá»¯ liá»‡u tá»« táº­p Train dÃ¹ng Ä‘á»ƒ kiá»ƒm tra trong lÃºc huáº¥n luyá»‡n."
    )

    if st.button("Chia tÃ¡ch dá»¯ liá»‡u"):
        mnist = st.session_state.mnist_data
        X, y = mnist.data / 255.0, mnist.target.astype(int)
        
        if sample_size < st.session_state.total_samples:
            X, _, y, _ = train_test_split(X, y, train_size=sample_size, random_state=42, stratify=y)
        
        st.session_state.X = X
        st.session_state.y = y

        X_train_full, X_test, y_train_full, y_test = train_test_split(
            st.session_state.X, st.session_state.y, test_size=test_size, random_state=42, stratify=st.session_state.y
        )
        X_train, X_valid, y_train, y_valid = train_test_split(
            X_train_full, y_train_full, test_size=valid_size, random_state=42, stratify=y_train_full
        )

        st.session_state.X_train = X_train
        st.session_state.X_valid = X_valid
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_valid = y_valid
        st.session_state.y_test = y_test
        st.session_state.data_split_done = True
        st.session_state.mnist_loaded = True

        st.write(f"Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia tÃ¡ch vá»›i {sample_size} máº«u!")
        st.write(f"- Dá»¯ liá»‡u Train: {st.session_state.X_train.shape} ({(1-test_size)*(1-valid_size)*100:.1f}%)")
        st.write(f"- Dá»¯ liá»‡u Validation: {st.session_state.X_valid.shape} ({(1-test_size)*valid_size*100:.1f}%)")
        st.write(f"- Dá»¯ liá»‡u Test: {st.session_state.X_test.shape} ({test_size*100:.1f}%)")

    st.subheader("VÃ­ dá»¥ hÃ¬nh áº£nh tá»« táº­p Train")
    if st.session_state.get("data_split_done", False):
        X = st.session_state.X_train
        y = st.session_state.y_train
        indices = random.sample(range(len(X)), 5)
        fig, axs = plt.subplots(1, 5, figsize=(12, 3))
        for i, idx in enumerate(indices):
            img = X[idx].reshape(28, 28)
            axs[i].imshow(img, cmap='gray')
            axs[i].axis('off')
            axs[i].set_title(f"Label: {y[idx]}")
        st.pyplot(fig)

    # Tab Huáº¥n luyá»‡n
    st.header("Huáº¥n luyá»‡n Neural Network")
    st.subheader("Cáº¥u hÃ¬nh huáº¥n luyá»‡n")
    num_epochs = st.number_input(
        "Sá»‘ epochs", 
        min_value=1, 
        max_value=50, 
        value=10,
        help="Sá»‘ láº§n mÃ´ hÃ¬nh há»c qua toÃ n bá»™ dá»¯ liá»‡u."
    )
    batch_size = st.selectbox(
        "Batch size", 
        [16, 32, 64, 128, 256, 512], 
        index=1,
        help="Sá»‘ máº«u xá»­ lÃ½ cÃ¹ng lÃºc."
    )
    learning_rate = st.number_input(
        "Tá»‘c Ä‘á»™ há»c (learning rate)", 
        min_value=0.0001, 
        max_value=0.1, 
        value=0.001, 
        step=0.0001,
        help="Kiá»ƒm soÃ¡t tá»‘c Ä‘á»™ há»c cá»§a mÃ´ hÃ¬nh."
    )
    num_hidden_layers = st.number_input(
        "Sá»‘ lá»›p áº©n", 
        min_value=1, 
        max_value=20,  # Giá»›i háº¡n tá»‘i Ä‘a há»£p lÃ½, cÃ³ thá»ƒ thay Ä‘á»•i
        value=1, 
        step=1,
        help="Sá»‘ lÆ°á»£ng lá»›p áº©n trong máº¡ng nÆ¡-ron (nháº­p sá»‘ báº¥t ká»³ tá»« 1 trá»Ÿ lÃªn)."
    )
    hidden_neurons = st.selectbox(
        "Sá»‘ nÆ¡-ron má»—i lá»›p áº©n", 
        [32, 64, 128, 256, 512], 
        index=2,
        help="Sá»‘ nÆ¡-ron trong má»—i lá»›p áº©n."
    )
    activation_function = st.selectbox(
        "HÃ m kÃ­ch hoáº¡t (Activation Function)",
        ["ReLU", "Sigmoid", "Tanh"],
        index=0,
        help="HÃ m biáº¿n Ä‘á»•i Ä‘áº§u ra cá»§a lá»›p áº©n."
    )

    experiment_name = st.text_input(
        "Nháº­p tÃªn cho thÃ­ nghiá»‡m MLflow", 
        value="",
        help="TÃªn Ä‘á»ƒ lÆ°u thÃ­ nghiá»‡m trong MLflow."
    )
    if not experiment_name:
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        experiment_name = f"Neural_Network_MNIST_{timestamp}"
    
    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        if not st.session_state.get("data_split_done", False):
            st.error("Vui lÃ²ng chia tÃ¡ch dá»¯ liá»‡u trÆ°á»›c!")
        else:
            X_train = st.session_state.X_train
            y_train = st.session_state.y_train
            X_valid = st.session_state.X_valid
            y_valid = st.session_state.y_valid
            X_test = st.session_state.X_test
            y_test = st.session_state.y_test

            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
            y_train_tensor = torch.tensor(y_train, dtype=torch.long)
            X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)
            y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)
            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
            y_test_tensor = torch.tensor(y_test, dtype=torch.long)

            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
            valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)
            valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)
            test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

            # Äá»‹nh nghÄ©a mÃ´ hÃ¬nh Neural Network
            class SimpleNN(nn.Module):
                def __init__(self, num_hidden_layers, hidden_size, activation):
                    super(SimpleNN, self).__init__()
                    layers = [nn.Linear(784, hidden_size)]
                    if activation == "ReLU":
                        layers.append(nn.ReLU())
                    elif activation == "Sigmoid":
                        layers.append(nn.Sigmoid())
                    elif activation == "Tanh":
                        layers.append(nn.Tanh())
                    for _ in range(num_hidden_layers - 1):
                        layers.append(nn.Linear(hidden_size, hidden_size))
                        if activation == "ReLU":
                            layers.append(nn.ReLU())
                        elif activation == "Sigmoid":
                            layers.append(nn.Sigmoid())
                        elif activation == "Tanh":
                            layers.append(nn.Tanh())
                    layers.append(nn.Linear(hidden_size, 10))
                    self.network = nn.Sequential(*layers)

                def forward(self, x):
                    return self.network(x)

            model = SimpleNN(num_hidden_layers=num_hidden_layers, hidden_size=hidden_neurons, activation=activation_function)
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.Adam(model.parameters(), lr=learning_rate)

            # Thiáº¿t láº­p MLflow
            mlflow.set_experiment(experiment_name)
            with mlflow.start_run() as run:
                # Log cÃ¡c tham sá»‘
                mlflow.log_param("num_epochs", num_epochs)
                mlflow.log_param("batch_size", batch_size)
                mlflow.log_param("learning_rate", learning_rate)
                mlflow.log_param("num_hidden_layers", num_hidden_layers)
                mlflow.log_param("hidden_neurons", hidden_neurons)
                mlflow.log_param("activation_function", activation_function)
                mlflow.log_param("test_size", test_size)
                mlflow.log_param("valid_size", valid_size)
                mlflow.log_param("sample_size", sample_size)

                progress_bar = st.progress(0)
                status_text = st.empty()

                train_acc_history = []
                valid_acc_history = []
                test_acc_history = []

                # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
                for epoch in range(num_epochs):
                    model.train()
                    correct = 0
                    total = 0
                    train_loss = 0
                    for inputs, labels in train_loader:
                        optimizer.zero_grad()
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)
                        loss.backward()
                        optimizer.step()
                        train_loss += loss.item()
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                    train_acc = correct / total
                    train_loss = train_loss / len(train_loader)
                    train_acc_history.append(train_acc)

                    # ÄÃ¡nh giÃ¡ trÃªn táº­p validation
                    model.eval()
                    correct = 0
                    total = 0
                    valid_loss = 0
                    with torch.no_grad():
                        for inputs, labels in valid_loader:
                            outputs = model(inputs)
                            valid_loss += criterion(outputs, labels).item()
                            _, predicted = torch.max(outputs.data, 1)
                            total += labels.size(0)
                            correct += (predicted == labels).sum().item()
                    valid_acc = correct / total
                    valid_loss = valid_loss / len(valid_loader)
                    valid_acc_history.append(valid_acc)

                    # ÄÃ¡nh giÃ¡ trÃªn táº­p test
                    correct = 0
                    total = 0
                    test_loss = 0
                    with torch.no_grad():
                        for inputs, labels in test_loader:
                            outputs = model(inputs)
                            test_loss += criterion(outputs, labels).item()
                            _, predicted = torch.max(outputs.data, 1)
                            total += labels.size(0)
                            correct += (predicted == labels).sum().item()
                    test_acc = correct / total
                    test_loss = test_loss / len(test_loader)
                    test_acc_history.append(test_acc)

                    # Log metrics vÃ o MLflow
                    mlflow.log_metric("train_accuracy", train_acc, step=epoch)
                    mlflow.log_metric("train_loss", train_loss, step=epoch)
                    mlflow.log_metric("valid_accuracy", valid_acc, step=epoch)
                    mlflow.log_metric("valid_loss", valid_loss, step=epoch)
                    mlflow.log_metric("test_accuracy", test_acc, step=epoch)
                    mlflow.log_metric("test_loss", test_loss, step=epoch)

                    progress = (epoch + 1) / num_epochs
                    progress_bar.progress(progress)
                    status_text.text(f"Epoch {epoch+1}/{num_epochs}, Train Acc: {train_acc:.4f}, Valid Acc: {valid_acc:.4f}, Test Acc: {test_acc:.4f}")

                # Log mÃ´ hÃ¬nh vÃ o MLflow
                mlflow.pytorch.log_model(model, "model")
                
                # LÆ°u mÃ´ hÃ¬nh vÃ o session_state Ä‘á»ƒ dÃ¹ng á»Ÿ cÃ¡c tab khÃ¡c
                st.session_state.model = model
                st.session_state.run_id = run.info.run_id  # LÆ°u run_id Ä‘á»ƒ tham chiáº¿u sau

                st.success("Huáº¥n luyá»‡n hoÃ n táº¥t! Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c log vÃ o MLflow.")

                # SÆ¡ Ä‘á»“ cáº¥u trÃºc mÃ´ hÃ¬nh
                st.subheader("SÆ¡ Ä‘á»“ cáº¥u trÃºc cÃ¡c lá»›p cá»§a mÃ´ hÃ¬nh")
                fig, ax = plt.subplots(figsize=(12, 5))
                model_dims = {"Input Layer": 784}
                for i in range(num_hidden_layers):
                    model_dims[f"Hidden Layer {i+1}\n({activation_function})"] = hidden_neurons
                model_dims["Output Layer"] = 10
                x_positions = np.linspace(0, 5, num_hidden_layers + 2)
                max_height = 2.0
                heights = [min(max_height, max_height * size / 784) for size in model_dims.values()]
                for i, (layer_name, size) in enumerate(model_dims.items()):
                    rect = patches.Rectangle(
                        (x_positions[i] - 0.4, -heights[i]/2), 0.8, heights[i],
                        linewidth=1, edgecolor='black', facecolor='lightblue'
                    )
                    ax.add_patch(rect)
                    ax.text(x_positions[i], heights[i]/2 + 0.2, f"{layer_name}\n{size} nÆ¡-ron", 
                            ha='center', va='bottom', fontsize=12)
                for i in range(len(x_positions) - 1):
                    ax.arrow(x_positions[i] + 0.4, 0, x_positions[i+1] - x_positions[i] - 0.8, 0, 
                             head_width=0.1, head_length=0.1, fc='black', ec='black')
                ax.set_xlim(-1, 6)
                ax.set_ylim(-max_height/2 - 0.5, max_height/2 + 0.8)
                ax.axis('off')
                st.pyplot(fig)

                # Biá»ƒu Ä‘á»“ Ä‘á»™ chÃ­nh xÃ¡c
                st.subheader("Biá»ƒu Ä‘á»“ Ä‘á»™ chÃ­nh xÃ¡c qua cÃ¡c epoch")
                fig, ax = plt.subplots()
                ax.plot(range(1, num_epochs+1), train_acc_history, label='Train Accuracy')
                ax.plot(range(1, num_epochs+1), valid_acc_history, label='Validation Accuracy')
                ax.plot(range(1, num_epochs+1), test_acc_history, label='Test Accuracy')
                ax.set_xlabel('Epoch')
                ax.set_ylabel('Accuracy')
                ax.legend()
                st.pyplot(fig)

                # Biá»ƒu Ä‘á»“ loss
                st.subheader("Biá»ƒu Ä‘á»“ Loss qua cÃ¡c epoch")
                fig, ax = plt.subplots()
                ax.plot(range(1, num_epochs+1), [train_acc_history[i] - train_loss for i in range(num_epochs)], label='Train Loss')
                ax.plot(range(1, num_epochs+1), [valid_acc_history[i] - valid_loss for i in range(num_epochs)], label='Validation Loss')
                ax.plot(range(1, num_epochs+1), [test_acc_history[i] - test_loss for i in range(num_epochs)], label='Test Loss')
                ax.set_xlabel('Epoch')
                ax.set_ylabel('Loss')
                ax.legend()
                st.pyplot(fig)

with tab3:
    # HÃ m tiá»n xá»­ lÃ½ áº£nh táº£i lÃªn
    def preprocess_uploaded_image(image):
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.resize(image, (28, 28))
        image = image.reshape(1, -1) / 255.0
        return image

    # HÃ m tiá»n xá»­ lÃ½ áº£nh tá»« canvas
    def preprocess_canvas_image(image_data):
        image = np.array(image_data)[:, :, 0]  # Láº¥y kÃªnh grayscale
        image = cv2.resize(image, (28, 28))
        image = image.reshape(1, -1) / 255.0
        return image

    # Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n chÆ°a
    if "model" not in st.session_state:
        st.error("âš ï¸ MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n! HÃ£y quay láº¡i tab 'Chia dá»¯ liá»‡u & Huáº¥n luyá»‡n' Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c.")
        st.stop()

    st.header("ğŸ–ï¸ Dá»± Ä‘oÃ¡n chá»¯ sá»‘ viáº¿t tay")
    option = st.radio("ğŸ–¼ï¸ Chá»n phÆ°Æ¡ng thá»©c nháº­p:", ["ğŸ“‚ Táº£i áº£nh lÃªn", "âœï¸ Váº½ sá»‘"])

    if option == "ğŸ“‚ Táº£i áº£nh lÃªn":
        uploaded_file = st.file_uploader("ğŸ“¤ Táº£i áº£nh sá»‘ viáº¿t tay (PNG, JPG)", type=["png", "jpg", "jpeg"])
        if uploaded_file is not None:
            image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
            processed_image = preprocess_uploaded_image(image)
            st.image(image, caption="ğŸ“· áº¢nh táº£i lÃªn", use_column_width=True)

            if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):
                model = st.session_state.model
                model.eval()
                with torch.no_grad():
                    input_tensor = torch.tensor(processed_image, dtype=torch.float32)
                    outputs = model(input_tensor)
                    probabilities = torch.softmax(outputs, dim=1).numpy()[0]
                    prediction = np.argmax(probabilities)
                    st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {prediction}**")
                    st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {probabilities[prediction] * 100:.2f}%**")

    elif option == "âœï¸ Váº½ sá»‘":
        # Sá»­ dá»¥ng st_canvas vá»›i cÃ¡c tham sá»‘ há»£p lá»‡
        canvas_result = st_canvas(
            fill_color="rgba(255, 255, 255, 0.0)",  # MÃ u tÃ´ (trong suá»‘t Ä‘á»ƒ khÃ´ng tÃ´ ná»n)
            stroke_width=15,                        # Äá»™ dÃ y nÃ©t váº½
            stroke_color="black",                   # MÃ u nÃ©t váº½
            background_color="white",               # MÃ u ná»n canvas
            width=280,                              # Chiá»u rá»™ng
            height=280,                             # Chiá»u cao
            drawing_mode="freedraw",                # Cháº¿ Ä‘á»™ váº½ tá»± do
            key="canvas"                            # KhÃ³a duy nháº¥t
        )
        if st.button("ğŸ”® Dá»± Ä‘oÃ¡n"):
            if canvas_result.image_data is not None:
                processed_canvas = preprocess_canvas_image(canvas_result.image_data)
                model = st.session_state.model
                model.eval()
                with torch.no_grad():
                    input_tensor = torch.tensor(processed_canvas, dtype=torch.float32)
                    outputs = model(input_tensor)
                    probabilities = torch.softmax(outputs, dim=1).numpy()[0]
                    prediction = np.argmax(probabilities)
                    st.write(f"ğŸ¯ **Dá»± Ä‘oÃ¡n: {prediction}**")
                    st.write(f"ğŸ”¢ **Äá»™ tin cáº­y: {probabilities[prediction] * 100:.2f}%**")

# Tab 3: MLflow
with tab4:
    st.header("Tracking MLflow")
    try:
        from mlflow.tracking import MlflowClient
        client = MlflowClient()

        # Láº¥y danh sÃ¡ch thÃ­ nghiá»‡m tá»« MLflow
        experiments = mlflow.search_experiments()

        if experiments:
            st.write("#### Danh sÃ¡ch thÃ­ nghiá»‡m")
            experiment_data = [
                {
                    "Experiment ID": exp.experiment_id,
                    "Experiment Name": exp.name,
                    "Artifact Location": exp.artifact_location
                }
                for exp in experiments
            ]
            df_experiments = pd.DataFrame(experiment_data)
            st.dataframe(df_experiments)

            # Chá»n thÃ­ nghiá»‡m dá»±a trÃªn TÃŠN thay vÃ¬ ID
            selected_exp_name = st.selectbox(
                "ğŸ” Chá»n thÃ­ nghiá»‡m Ä‘á»ƒ xem chi tiáº¿t",
                options=[exp.name for exp in experiments]
            )

            # Láº¥y ID tÆ°Æ¡ng á»©ng vá»›i tÃªn Ä‘Æ°á»£c chá»n
            selected_exp_id = next(exp.experiment_id for exp in experiments if exp.name == selected_exp_name)

            # Láº¥y danh sÃ¡ch runs trong thÃ­ nghiá»‡m Ä‘Ã£ chá»n
            runs = mlflow.search_runs(selected_exp_id)
            if not runs.empty:
                st.write("#### Danh sÃ¡ch runs")
                st.dataframe(runs)

                # Chá»n run Ä‘á»ƒ xem chi tiáº¿t
                selected_run_id = st.selectbox(
                    "ğŸ” Chá»n run Ä‘á»ƒ xem chi tiáº¿t",
                    options=runs["run_id"]
                )

                # Hiá»ƒn thá»‹ chi tiáº¿t run
                run = mlflow.get_run(selected_run_id)
                st.write("##### ThÃ´ng tin run")
                st.write(f"*Run ID:* {run.info.run_id}")
                st.write(f"*Experiment ID:* {run.info.experiment_id}")
                st.write(f"*Start Time:* {run.info.start_time}")

                # Hiá»ƒn thá»‹ metrics
                st.write("##### Metrics")
                st.json(run.data.metrics)

                # Hiá»ƒn thá»‹ params
                st.write("##### Params")
                st.json(run.data.params)

                # Hiá»ƒn thá»‹ artifacts sá»­ dá»¥ng client.list_artifacts
                artifacts = client.list_artifacts(selected_run_id)
                if artifacts:
                    st.write("##### Artifacts")
                    for artifact in artifacts:
                        st.write(f"- {artifact.path}")
            else:
                st.warning("KhÃ´ng cÃ³ runs nÃ o trong thÃ­ nghiá»‡m nÃ y.")
        else:
            st.warning("KhÃ´ng cÃ³ thÃ­ nghiá»‡m nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y.")
    except Exception as e:
        st.error(f"ÄÃ£ xáº£y ra lá»—i khi láº¥y danh sÃ¡ch thÃ­ nghiá»‡m: {e}")